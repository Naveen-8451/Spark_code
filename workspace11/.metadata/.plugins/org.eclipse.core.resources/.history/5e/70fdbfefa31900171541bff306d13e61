package org.draft.Dev_Env

import java.sql.DriverManager
import java.sql.Connection
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.sql.SQLContext


object sourcing {

  def main(args: Array[String]) {
    // connect to the database named "mysql" on the localhost
    val driver = "com.mysql.cj.jdbc.Driver"
    val url = "jdbc:mysql://localhost/Movie?useUnicode=true&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=UTC"
    val username = "scott"
    val password = "tiger"
    val conf = new SparkConf().setAppName("sourcing").setMaster("local[*]")
    val sc = new SparkContext(conf)
    val sqlContext = new SQLContext(sc)
    import sqlContext.implicits._
    // there's probably a better way to do this
    var connection:Connection = null
    
    try {
      // make the connection
      Class.forName(driver)
      connection = DriverManager.getConnection(url, username, password)
      val DataRdd = sqlContext.read.format("jdbc").option("url",url).option("driver",driver).option("dbtable","genre").option("user",username).option("password",password).load()
      DataRdd.registerTempTable("temp_genre")
      val SaveRdd = sqlContext.sql("select * from genre")
      SaveRdd.write.format("parquet").save("/Users/divyakasireddy/Documents/workspace11/DEV/Reference/genre/")
    } catch {
      case e => e.printStackTrace
    }
    connection.close()
  }

}