package org.draft.Dev_Env

import java.sql.DriverManager
import java.sql.Connection
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.sql.SQLContext
import org.apache.commons.io.FileUtils._
import org.apache.commons.io.filefilter.WildcardFileFilter
import java.io.File
import org.apache.commons.io.FileUtils

object sourcing {

  
  def main(args: Array[String]) {
     
    // connect to the database named "mysql" on the localhost
    
    val database =  readLine("Please enter Database Name:")
    val table = readLine("Enter Mysql Database Table:")
    var location = "/Users/divyakasireddy/Documents/workspace11/DEV/Reference/"+table+"/"
    var status = new java.io.File(location).exists()
    if (status == true)
    {
      println (" Deleting directory : " +location)
      FileUtils.deleteDirectory(new File(location.toString()))   
      }
    val driver = "com.mysql.cj.jdbc.Driver"
    val url = "jdbc:mysql://localhost/"+database+"?useUnicode=true&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=UTC"
    val username = "scott"
    val password = "tiger"
    val conf = new SparkConf().setAppName("sourcing").setMaster("local[*]")
    val sc = new SparkContext(conf)
    val sqlContext = new SQLContext(sc)
    import sqlContext.implicits._
    // there's probably a better way to do this
    var connection:Connection = null
    
    try {
      // make the connection
      Class.forName(driver)
      connection = DriverManager.getConnection(url, username, password)
      val DataRdd = sqlContext.read.format("jdbc").option("url",url).option("driver",driver).option("dbtable",table).option("user",username).option("password",password).load()
      DataRdd.registerTempTable(table)
      val SaveRdd = sqlContext.sql("select * from "+ table)
      SaveRdd.write.format("parquet").save(location)
    } catch {
      case e => e.printStackTrace
    }
    connection.close()
  }

}